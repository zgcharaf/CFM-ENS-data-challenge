{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7977791,"sourceType":"datasetVersion","datasetId":4695158}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-11T10:57:15.637428Z","iopub.execute_input":"2024-05-11T10:57:15.637726Z","iopub.status.idle":"2024-05-11T10:57:17.503235Z","shell.execute_reply.started":"2024-05-11T10:57:15.637698Z","shell.execute_reply":"2024-05-11T10:57:17.502306Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/cfmens/X_test_m4HAPAP.csv\n/kaggle/input/cfmens/y_train_or6m3Ta.csv\n/kaggle/input/cfmens/X_train_N1UvY30.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import polars as pl\n\n# Load datasets\nx_train_path = '/kaggle/input/cfmens/X_train_N1UvY30.csv'\nx_test_path = '/kaggle/input/cfmens/X_test_m4HAPAP.csv'\nX_train = pl.scan_csv(x_train_path)\n\n# Function to add feature engineering to a Polars DataFrame\ndef add_feature_engineering(df):\n    # Statistical Features\n    for col in ['price', 'bid', 'ask', 'bid_size', 'ask_size', 'flux']:\n        df = df.with_columns([\n            pl.col(col).mean().over('obs_id').alias(f'{col}_mean'),\n            pl.col(col).std().over('obs_id').alias(f'{col}_std'),\n            (pl.col(col).max().over('obs_id') - pl.col(col).min().over('obs_id')).alias(f'{col}_range')\n        ])\n    \n    # Imbalance Metrics\n    df = df.with_columns([\n        (pl.col('bid_size') - pl.col('ask_size')).alias('imbalance'),\n        (pl.col('bid_size') / (pl.col('ask_size') + 0.01)).alias('imbalance_ratio')  # Avoid division by zero\n    ])\n    \n    # Recent Price Change\n    # Assuming each group 'obs_id' is already sorted by time\n    df = df.with_columns(\n        (pl.col('price').last().over('obs_id') - pl.col('price').first().over('obs_id')).alias('price_change')\n    )\n    \n    # VWAP\n    vwap = (pl.col('price') * pl.col('flux')).sum().over('obs_id') / pl.col('flux').sum().over('obs_id')\n    df = df.with_columns(vwap.alias('vwap'))\n    \n    return df\n\n# Apply feature engineering\nX_train_fe = add_feature_engineering(X_train)\n \n# Note: The function assumes 'obs_id' or an equivalent exists to group by sequences.\n# You might need to adjust it according to your actual dataset structure.\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:50:21.409062Z","iopub.execute_input":"2024-04-03T19:50:21.409583Z","iopub.status.idle":"2024-04-03T19:50:21.653511Z","shell.execute_reply.started":"2024-04-03T19:50:21.409554Z","shell.execute_reply":"2024-04-03T19:50:21.652664Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"categorical_columns = ['venue', 'action', 'side','trade']\n\nfor col in categorical_columns:\n    X_train = X_train.with_columns(pl.col(col).cast(pl.Utf8).cast(pl.Categorical).alias(col))\n\n# To one-hot encode, we can use `to_dummies` (similar to pandas get_dummies)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:50:29.652332Z","iopub.execute_input":"2024-04-03T19:50:29.653187Z","iopub.status.idle":"2024-04-03T19:50:29.660675Z","shell.execute_reply.started":"2024-04-03T19:50:29.653154Z","shell.execute_reply":"2024-04-03T19:50:29.659680Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_train_p = X_train.collect().to_pandas()","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:50:31.419718Z","iopub.execute_input":"2024-04-03T19:50:31.420532Z","iopub.status.idle":"2024-04-03T19:50:41.127091Z","shell.execute_reply.started":"2024-04-03T19:50:31.420498Z","shell.execute_reply":"2024-04-03T19:50:41.125980Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_train_encoded = pd.get_dummies(X_train_p, columns=['venue', 'action', 'side','trade']).drop(['obs_id'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:02:14.227610Z","iopub.execute_input":"2024-04-03T19:02:14.228552Z","iopub.status.idle":"2024-04-03T19:02:16.925071Z","shell.execute_reply.started":"2024-04-03T19:02:14.228512Z","shell.execute_reply":"2024-04-03T19:02:16.923827Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Assuming y_train is loaded and you have the encoded X_train\n# Ensure X_train_encoded is a NumPy array for reshaping\nX_train_np = X_train_encoded.to_numpy()\n\n# Assuming each sequence is 100 observations long\nnum_sequences = int(X_train_np.shape[0] / 100)\nnum_features = X_train_np.shape[1]  # Number of features after encoding\n\n# Reshape X_train to have dimensions: (num_sequences, 100, num_features)\nX_train_reshaped = X_train_np.reshape((num_sequences, 100, num_features))\n\n# Proceed with model training using the reshaped X_train_reshaped\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:02:28.555327Z","iopub.execute_input":"2024-04-03T19:02:28.556274Z","iopub.status.idle":"2024-04-03T19:02:41.041389Z","shell.execute_reply.started":"2024-04-03T19:02:28.556220Z","shell.execute_reply":"2024-04-03T19:02:41.040590Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Path to your y_train CSV file\ny_train_path = '/kaggle/input/cfmens/y_train_or6m3Ta.csv'\n\n# Read y_train using Pandas\ny_train_df = pd.read_csv(y_train_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:34:03.647643Z","iopub.execute_input":"2024-04-03T19:34:03.648070Z","iopub.status.idle":"2024-04-03T19:34:03.694525Z","shell.execute_reply.started":"2024-04-03T19:34:03.648039Z","shell.execute_reply":"2024-04-03T19:34:03.693231Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"y_train_df.iloc[:, -1]","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:04:29.021969Z","iopub.execute_input":"2024-04-03T19:04:29.022706Z","iopub.status.idle":"2024-04-03T19:04:29.031021Z","shell.execute_reply.started":"2024-04-03T19:04:29.022669Z","shell.execute_reply":"2024-04-03T19:04:29.030098Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0         10\n1         15\n2          0\n3         13\n4          0\n          ..\n160795    13\n160796     1\n160797     3\n160798    11\n160799     5\nName: eqt_code_cat, Length: 160800, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n\n\n# Assuming y_train_df contains a single column with labels\n# If y_train_df contains multiple columns or the label column is not the first one,\n# adjust the column selection accordingly.\ny_train = y_train_df.iloc[:, -1].values  # This extracts the labels as a NumPy array\n\n# Since every 100 observations in X_train correspond to a single label in y_train,\n# and assuming the observations are evenly distributed among the labels,\n# we don't need to reshape y_train, but we should ensure its length matches the reshaped X_train's\nnum_sequences = int(X_train_reshaped.shape[0])\n\n# Check if y_train length matches the number of sequences\nassert len(y_train) == num_sequences, \"The length of y_train does not match the number of sequences in X_train.\"\n\n# At this point, y_train is ready and properly aligned with X_train_reshaped for model training.\n\n# Optionally, convert y_train to categorical if it represents classes\nfrom tensorflow.keras.utils import to_categorical\n\n# Determine the number of classes for y_train\nnum_classes = np.unique(y_train).size\n\n# Convert labels to one-hot encoding\ny_train_categorical = to_categorical(y_train, num_classes=num_classes)\n\n# y_train_categorical is now ready to be used with your model.\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:04:37.636591Z","iopub.execute_input":"2024-04-03T19:04:37.637560Z","iopub.status.idle":"2024-04-03T19:04:49.656254Z","shell.execute_reply.started":"2024-04-03T19:04:37.637520Z","shell.execute_reply":"2024-04-03T19:04:49.655076Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"2024-04-03 19:04:39.381975: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-03 19:04:39.382094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-03 19:04:39.508099: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Bidirectional, GRU, Dense, Dropout\n\n# Define the model\nmodel = Sequential([\n    # Add a Bidirectional GRU layer\n    Bidirectional(GRU(64, return_sequences=True), input_shape=(100, X_train_reshaped.shape[2])),\n    Dropout(0.2),  # Dropout for regularization\n    Bidirectional(GRU(32)),\n    Dropout(0.2),  # Another Dropout layer for regularization\n    # Output layer, assuming `num_classes` is defined from y_train preparation\n    Dense(num_classes, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Model summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:05:51.070408Z","iopub.execute_input":"2024-04-03T19:05:51.071188Z","iopub.status.idle":"2024-04-03T19:05:52.591149Z","shell.execute_reply.started":"2024-04-03T19:05:51.071153Z","shell.execute_reply":"2024-04-03T19:05:52.590199Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m33,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m31,104\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m1,560\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,104</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,560</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,688\u001b[0m (256.59 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,688</span> (256.59 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,688\u001b[0m (256.59 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,688</span> (256.59 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"X_train_reshaped = X_train_reshaped.astype(int)\nhistory = model.fit(\n    X_train_reshaped, \n    y_train_categorical, \n    epochs=10,  # Number of epochs: adjust based on your data and training progress\n    batch_size=64,  # Batch size: adjust based on your data and available memory\n    validation_split=0.2  # Use 20% of the data for validation\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:14:05.981762Z","iopub.execute_input":"2024-04-03T19:14:05.982118Z","iopub.status.idle":"2024-04-03T19:20:16.680624Z","shell.execute_reply.started":"2024-04-03T19:14:05.982090Z","shell.execute_reply":"2024-04-03T19:20:16.679225Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 19ms/step - accuracy: 0.4003 - loss: 1.8253 - val_accuracy: 0.4365 - val_loss: 1.7399\nEpoch 2/10\n\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 18ms/step - accuracy: 0.4121 - loss: 1.7980 - val_accuracy: 0.4491 - val_loss: 1.7046\nEpoch 3/10\n\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 18ms/step - accuracy: 0.4235 - loss: 1.7629 - val_accuracy: 0.4566 - val_loss: 1.6804\nEpoch 4/10\n\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 18ms/step - accuracy: 0.4262 - loss: 1.7486 - val_accuracy: 0.4538 - val_loss: 1.6681\nEpoch 5/10\n\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 18ms/step - accuracy: 0.4299 - loss: 1.7264 - val_accuracy: 0.4531 - val_loss: 1.6940\nEpoch 6/10\n\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 18ms/step - accuracy: 0.4369 - loss: 1.7191 - val_accuracy: 0.4682 - val_loss: 1.6392\nEpoch 7/10\n\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 18ms/step - accuracy: 0.4415 - loss: 1.6944 - val_accuracy: 0.4829 - val_loss: 1.5840\nEpoch 8/10\n\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 18ms/step - accuracy: 0.4507 - loss: 1.6743 - val_accuracy: 0.4749 - val_loss: 1.5973\nEpoch 9/10\n\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 19ms/step - accuracy: 0.4552 - loss: 1.6530 - val_accuracy: 0.4880 - val_loss: 1.5603\nEpoch 10/10\n\u001b[1m2010/2010\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 18ms/step - accuracy: 0.4619 - loss: 1.6340 - val_accuracy: 0.4922 - val_loss: 1.5543\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Path to your X_test CSV file\nx_test_path = '/kaggle/input/cfmens/X_test_m4HAPAP.csv'\n\n# Load X_test using Pandas\nX_test = pd.read_csv(x_test_path)\n\n# One-hot encode categorical variables in X_test just like X_train\nX_test_encoded = pd.get_dummies(X_test, columns=['venue', 'action', 'side', 'trade']).drop(['obs_id'], axis=1)\n\n# Ensure X_test_encoded has the same columns in the same order as X_train_encoded\n# This step is crucial because the model expects the same feature set in training and prediction\n# There might be missing columns if some categories are not present in the test data\nmissing_cols = set(X_train_encoded.columns) - set(X_test_encoded.columns)\nfor c in missing_cols:\n    X_test_encoded[c] = 0  # Add missing columns as zeros\n\n# Reorder X_test_encoded columns to match X_train_encoded\nX_test_encoded = X_test_encoded[X_train_encoded.columns]\n\n# Convert X_test_encoded to a numpy array and reshape for the model\nX_test_np = X_test_encoded.to_numpy()\n\n# Assuming each sequence is 100 observations long, reshape X_test\nnum_sequences_test = int(X_test_np.shape[0] / 100)\nX_test_reshaped = X_test_np.reshape((num_sequences_test, 100, X_test_encoded.shape[1]))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:30:04.188904Z","iopub.execute_input":"2024-04-03T19:30:04.189304Z","iopub.status.idle":"2024-04-03T19:30:29.686628Z","shell.execute_reply.started":"2024-04-03T19:30:04.189275Z","shell.execute_reply":"2024-04-03T19:30:29.685460Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"X_test_reshaped = X_test_reshaped.astype(int)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:31:30.921555Z","iopub.execute_input":"2024-04-03T19:31:30.921979Z","iopub.status.idle":"2024-04-03T19:31:41.291234Z","shell.execute_reply.started":"2024-04-03T19:31:30.921946Z","shell.execute_reply":"2024-04-03T19:31:41.289806Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"X_test_reshaped","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:31:42.380938Z","iopub.execute_input":"2024-04-03T19:31:42.381316Z","iopub.status.idle":"2024-04-03T19:31:42.389977Z","shell.execute_reply.started":"2024-04-03T19:31:42.381287Z","shell.execute_reply":"2024-04-03T19:31:42.389007Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"array([[[ 0,  0,  0, ...,  0,  0,  0],\n        [ 1,  0,  0, ...,  0,  0,  0],\n        [ 2,  1,  0, ...,  0,  0,  0],\n        ...,\n        [48,  0,  0, ...,  1,  0,  0],\n        [51,  0,  0, ...,  0,  0,  0],\n        [50,  0,  0, ...,  0,  0,  0]],\n\n       [[ 0,  0,  0, ...,  0,  0,  0],\n        [ 1,  0,  0, ...,  0,  0,  0],\n        [ 2,  0,  0, ...,  1,  0,  0],\n        ...,\n        [24,  0,  0, ...,  0,  0,  0],\n        [26,  0,  0, ...,  0,  0,  0],\n        [68,  0,  0, ...,  0,  0,  0]],\n\n       [[ 0,  0,  0, ...,  1,  0,  0],\n        [ 1,  0,  0, ...,  1,  0,  0],\n        [ 2,  0,  0, ...,  1,  0,  0],\n        ...,\n        [60,  0,  0, ...,  1,  0,  0],\n        [61,  0,  0, ...,  1,  0,  0],\n        [58,  0,  0, ...,  1,  0,  0]],\n\n       ...,\n\n       [[ 0,  0,  0, ...,  1,  0,  0],\n        [ 1, -1,  0, ...,  1,  0,  0],\n        [ 2, -1,  0, ...,  1,  0,  0],\n        ...,\n        [63,  0,  0, ...,  1,  0,  0],\n        [63,  0,  0, ...,  1,  0,  0],\n        [64,  0,  0, ...,  1,  0,  0]],\n\n       [[ 0,  0,  0, ...,  1,  0,  0],\n        [ 1,  0,  0, ...,  1,  0,  0],\n        [ 2,  0,  0, ...,  0,  0,  0],\n        ...,\n        [41,  0,  0, ...,  1,  0,  0],\n        [43,  0,  0, ...,  1,  0,  0],\n        [75,  0,  0, ...,  1,  0,  0]],\n\n       [[ 0,  0,  0, ...,  1,  0,  0],\n        [ 1,  0,  0, ...,  1,  0,  0],\n        [ 1,  0,  0, ...,  1,  0,  0],\n        ...,\n        [58,  0,  0, ...,  0,  0,  0],\n        [59,  0,  0, ...,  0,  0,  0],\n        [60,  0,  0, ...,  0,  0,  0]]])"},"metadata":{}}]},{"cell_type":"code","source":"# Make predictions\npredictions = model.predict(X_test_reshaped)\n\n# If your model outputs one-hot encoded predictions, convert these to label predictions\n# Assuming your model does classification\npredicted_labels = predictions.argmax(axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:31:45.581184Z","iopub.execute_input":"2024-04-03T19:31:45.581955Z","iopub.status.idle":"2024-04-03T19:32:05.867200Z","shell.execute_reply.started":"2024-04-03T19:31:45.581911Z","shell.execute_reply":"2024-04-03T19:32:05.866180Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"\u001b[1m2550/2550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 6ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example: Save predictions to CSV for submission\nsubmission_df = pd.DataFrame(predicted_labels, columns=['eqt_code_cat'])\nsubmission_df.to_csv('submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:35:06.240741Z","iopub.execute_input":"2024-04-03T19:35:06.241442Z","iopub.status.idle":"2024-04-03T19:35:06.342990Z","shell.execute_reply.started":"2024-04-03T19:35:06.241410Z","shell.execute_reply":"2024-04-03T19:35:06.342117Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"y_train_df","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:34:14.720497Z","iopub.execute_input":"2024-04-03T19:34:14.721353Z","iopub.status.idle":"2024-04-03T19:34:14.732262Z","shell.execute_reply.started":"2024-04-03T19:34:14.721315Z","shell.execute_reply":"2024-04-03T19:34:14.731239Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"        obs_id  eqt_code_cat\n0            0            10\n1            1            15\n2            2             0\n3            3            13\n4            4             0\n...        ...           ...\n160795  160795            13\n160796  160796             1\n160797  160797             3\n160798  160798            11\n160799  160799             5\n\n[160800 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>obs_id</th>\n      <th>eqt_code_cat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>160795</th>\n      <td>160795</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>160796</th>\n      <td>160796</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>160797</th>\n      <td>160797</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>160798</th>\n      <td>160798</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>160799</th>\n      <td>160799</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>160800 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train_encoded","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:42:57.070594Z","iopub.execute_input":"2024-04-03T19:42:57.071577Z","iopub.status.idle":"2024-04-03T19:42:57.098232Z","shell.execute_reply.started":"2024-04-03T19:42:57.071533Z","shell.execute_reply":"2024-04-03T19:42:57.097141Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"          order_id  price   bid   ask  bid_size  ask_size  flux  venue_4  \\\n0                0   0.30  0.00  0.01       100         1   100     True   \n1                1  -0.17  0.00  0.01       100         1   100     True   \n2                2   0.28  0.00  0.01       100         1  -100     True   \n3                3   0.30  0.00  0.01       100         1   100     True   \n4                4   0.37  0.00  0.01       100         1  -100     True   \n...            ...    ...   ...   ...       ...       ...   ...      ...   \n16079995        61   1.32  0.01  0.06       735       261  -100     True   \n16079996        70   0.06  0.01  0.06       735       361   100    False   \n16079997        71   1.26  0.01  0.06       735       361   100     True   \n16079998        72   1.26  0.01  0.06       735       361   100     True   \n16079999        73   0.00  0.01  0.06       635       361     1     True   \n\n          venue_1  venue_5  venue_2  venue_0  venue_3  action_A  action_D  \\\n0           False    False    False    False    False      True     False   \n1           False    False    False    False    False      True     False   \n2           False    False    False    False    False     False      True   \n3           False    False    False    False    False      True     False   \n4           False    False    False    False    False     False      True   \n...           ...      ...      ...      ...      ...       ...       ...   \n16079995    False    False    False    False    False     False      True   \n16079996    False    False    False     True    False      True     False   \n16079997    False    False    False    False    False      True     False   \n16079998    False    False    False    False    False      True     False   \n16079999    False    False    False    False    False      True     False   \n\n          action_U  side_A  side_B  trade_false  trade_true  \n0            False    True   False         True       False  \n1            False   False    True         True       False  \n2            False    True   False         True       False  \n3            False    True   False         True       False  \n4            False    True   False         True       False  \n...            ...     ...     ...          ...         ...  \n16079995     False    True   False         True       False  \n16079996     False    True   False         True       False  \n16079997     False    True   False         True       False  \n16079998     False    True   False         True       False  \n16079999     False   False    True         True       False  \n\n[16080000 rows x 20 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order_id</th>\n      <th>price</th>\n      <th>bid</th>\n      <th>ask</th>\n      <th>bid_size</th>\n      <th>ask_size</th>\n      <th>flux</th>\n      <th>venue_4</th>\n      <th>venue_1</th>\n      <th>venue_5</th>\n      <th>venue_2</th>\n      <th>venue_0</th>\n      <th>venue_3</th>\n      <th>action_A</th>\n      <th>action_D</th>\n      <th>action_U</th>\n      <th>side_A</th>\n      <th>side_B</th>\n      <th>trade_false</th>\n      <th>trade_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.30</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>100</td>\n      <td>1</td>\n      <td>100</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-0.17</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>100</td>\n      <td>1</td>\n      <td>100</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.28</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>100</td>\n      <td>1</td>\n      <td>-100</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.30</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>100</td>\n      <td>1</td>\n      <td>100</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.37</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>100</td>\n      <td>1</td>\n      <td>-100</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16079995</th>\n      <td>61</td>\n      <td>1.32</td>\n      <td>0.01</td>\n      <td>0.06</td>\n      <td>735</td>\n      <td>261</td>\n      <td>-100</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>16079996</th>\n      <td>70</td>\n      <td>0.06</td>\n      <td>0.01</td>\n      <td>0.06</td>\n      <td>735</td>\n      <td>361</td>\n      <td>100</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>16079997</th>\n      <td>71</td>\n      <td>1.26</td>\n      <td>0.01</td>\n      <td>0.06</td>\n      <td>735</td>\n      <td>361</td>\n      <td>100</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>16079998</th>\n      <td>72</td>\n      <td>1.26</td>\n      <td>0.01</td>\n      <td>0.06</td>\n      <td>735</td>\n      <td>361</td>\n      <td>100</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>16079999</th>\n      <td>73</td>\n      <td>0.00</td>\n      <td>0.01</td>\n      <td>0.06</td>\n      <td>635</td>\n      <td>361</td>\n      <td>1</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>16080000 rows × 20 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.utils import to_categorical\n\n \n\n# Encode Categorical Variables using get_dummies for X_train\n \n# Standardize Features\nscaler = StandardScaler()\nX_flat = X_train_encoded.values.reshape(-1, X_train_encoded.shape[1])\nX_standardized = scaler.fit_transform(X_flat)\n\n# Reshape Data to match the neural network's expected input\nnum_sequences = int(X_flat.shape[0] / 100)\nnum_features = X_standardized.shape[1]\nX_train_reshaped = X_standardized.reshape(num_sequences, 100, num_features)\n\n# Convert y_train to categorical if it represents classes\nnum_classes = len(np.unique(y_train))\ny_train_categorical = to_categorical(y_train, num_classes=num_classes)\n\n# Advanced Feature Engineering (Statistical Features Example)\n# Assuming a simple function to calculate a rolling mean as an example\ndef add_rolling_mean_feature(data, window_size=5):\n    rolling_means = np.mean(data.reshape(-1, window_size, data.shape[-1]), axis=1)\n    # Reshape to concatenate with the original data\n    rolling_means_repeated = np.repeat(rolling_means, window_size, axis=0)\n    return np.concatenate([data, rolling_means_repeated.reshape(data.shape)], axis=-1)\n\n# Apply feature engineering\nX_train_engineered = add_rolling_mean_feature(X_train_reshaped)\n\n# Data Augmentation (Simple Noise Addition Example)\ndef augment_data(data, noise_level=0.01):\n    noise = np.random.normal(loc=0.0, scale=noise_level, size=data.shape)\n    return data + noise\n\nX_train_augmented = augment_data(X_train_engineered)\n\n# Assuming the model is already defined and compiled as `model`\nhistory = model.fit(\n    X_train_augmented, \n    y_train_categorical, \n    epochs=10, \n    batch_size=32, \n    validation_split=0.2\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-03T19:43:14.862222Z","iopub.execute_input":"2024-04-03T19:43:14.862608Z"},"trusted":true},"execution_count":null,"outputs":[]}]}